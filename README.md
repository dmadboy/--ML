# 机器学习
- 《超智能体》
- 智能--能随着外部环境的变化而做出相应改变的能力--熵减的能力
- 太极生两仪，两仪生四象，四象生八卦
- 人类认知所在的维度并非信息的全部，所有的信息包含了所有已发生和可能发生的信息。而经典计算机只有已发生的状态信息。
- 熵增是不确定性的增加，不确定性的增加是信息的增加，信息的增加是因素间关系的增加；
- 学习的过程是因素间的关系的拆分，关系的拆分是信息的回卷，信息的回卷是不确定性的缩减；
- 学习的对象是知识，不是信息。--学习的目的是确定状态的关系
- 生物以负熵为生，学习是我们的本性
- 文字只是交流的手段，交流的前提是彼此都有该记忆。产生共鸣
- 智能可以并行，唯独意识不可以同时出现在两个位置
- 没有免费的午餐-any two optimization algorithms are equivalent when their performance is averaged across all possible problems.--对某个问题高效的优化算法一定在另一个问题上存在缺陷，不可能对所有问题都有效
## 线性代数的重要性
- 线性变换--最最最重要的概念
- y=Ax--列向量x左乘一个A矩阵得到一个列向量y
Ax同时也是深层神经网络每层变换的核心y=a(Ax+b)
## 概率
- 概率--衡量我们对事物在跨时间后不同状态的确信度
- 随机变量--给定一个样本空间Ω一个随机变量（r.v.）是将样本空间投射到实数域的函数。
- 概率五要件--
样本空间：所有可能结果组成的集合
随机变量：将事件投向实数的函数，用数字代表事件。
事件：样本空间的子集
概率：将事件投向【0，1】实数域的函数。用实数表示确信度
分布：随机变量的取值情况
![](http://pic1.zhimg.com/v2-c4bf85890918ede7952697c4d5e88618_r.jpg)
## 香农熵
H(X)=-∑Pi(X)logpi(x)
## 神经元的基本行为
y=a(W*x+b)--x是输入信号（向量），y是输出信号（向量），b是阀值（向量），W是神经元各个链接的强弱（频率），a()是化学传递（激活函数）
## 深度学习
[http://www.deeplearningbook.org](http://www.deeplearningbook.org)